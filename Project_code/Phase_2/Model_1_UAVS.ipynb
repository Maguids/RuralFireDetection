{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a35791-4f57-4efd-81d4-ce871a7ad21f",
   "metadata": {},
   "source": [
    "# Recriar Estudo 2 - Treino com o UAVS (Raw Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bce6ac-eb3d-484d-9fba-0ce4638f216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1db65b-e46e-4687-8a46-842669a79717",
   "metadata": {},
   "source": [
    "**Ver se está a usar a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775613f9-11c0-44c1-9f39-22c75604ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7f2f9-a20f-4342-944d-fc72e88f0af1",
   "metadata": {},
   "source": [
    "**imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2572ebb-43f4-476d-9fb0-0f6370e4af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Ativa o alocador assíncrono (melhora fragmentação de memória)\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "import tensorflow as tf\n",
    "# Ativa a alocação dinâmica de memória (não ocupa toda a memória no início)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Erro ao definir memory growth:\", e)\n",
    "from tensorflow.keras.layers import Input, Conv2D, DepthwiseConv2D, GlobalAveragePooling2D, Dense, ReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"TensorFlow Addons:\", tfa.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a131384-70c4-45ec-ac80-f8e9198900d1",
   "metadata": {},
   "source": [
    "## Arquitetura do Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721ad39-f1cd-4a22-95e8-8e0d53704d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrada\n",
    "input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "# Primeira camada\n",
    "x = Conv2D(48, (3,3), strides=2, padding='same')(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=3, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(24, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(72, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=3, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(24, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# ConvBlock_1\n",
    "for _ in range(2):\n",
    "    x = Conv2D(72, (1,1), strides=1, padding='same')(x)  # 24 -> 72\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = DepthwiseConv2D(kernel_size=3, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(24, (1,1), strides=1, padding='same')(x)  # 72 -> 24\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    \n",
    "# Expandir de novo\n",
    "x = Conv2D(72, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(56, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# ConvBlock_2\n",
    "for _ in range(2):\n",
    "    x = Conv2D(168, (1,1), strides=1, padding='same')(x)  # 56 -> 168\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel_size=5, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(56, (1,1), strides=1, padding='same')(x)  # 168 -> 56\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "# Expandir de novo\n",
    "x = Conv2D(336, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(104, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# ConvBlock_3\n",
    "for _ in range(2):\n",
    "    x = Conv2D(624, (1,1), strides=1, padding='same')(x)  # 104 -> 624\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)    \n",
    "    x = DepthwiseConv2D(kernel_size=5, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)    \n",
    "    x = Conv2D(104, (1,1), strides=1, padding='same')(x)  # 624 -> 104\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "# Expandir\n",
    "x = Conv2D(624, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=3, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(136, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# ConvBlock_4\n",
    "x = Conv2D(816, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=3, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(136, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Entre conv_blocks\n",
    "x = Conv2D(816, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=5, strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(272, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# ConvBlock_5\n",
    "for _ in range(3):\n",
    "    x = Conv2D(1632, (1,1), strides=1, padding='same')(x)  # 272 -> 1632\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel_size=5, strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "    x = Conv2D(272, (1,1), strides=1, padding='same')(x)  # 1632 -> 272\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "\n",
    "# Finalização\n",
    "x = Conv2D(1632, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = DepthwiseConv2D(kernel_size=3, strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(448, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "x = Conv2D(1280, (1,1), strides=1, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = ReLU()(x)\n",
    "\n",
    "# Pooling global e classificação\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_layer = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# Modelo\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b26bfd-e7bd-448e-9862-99a59ece00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tfa.metrics.F1Score(num_classes=2, average='macro')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c855bb-b8db-441f-8e95-7b8a966dd951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2c7bb-b824-4c0b-8a30-3adf43feb167",
   "metadata": {},
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059b75e-c052-4e98-8321-9a86498aabb0",
   "metadata": {},
   "source": [
    "Trata do pré-processamento das imagens, ou seja redimensiona para 224 X 224 pixels e normaliza [0,1] e coloca em one hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0721c0a-5321-45cc-a301-b6281f40044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função auxiliar para carregar imagem\n",
    "def preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = image / 255.0\n",
    "    label = tf.one_hot(label, 2)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09965d75-99bf-4305-bce4-812851f38c34",
   "metadata": {},
   "source": [
    "Permite analisar a distribuição dos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183b8f6-3af3-4537-ac18-9d56ae26e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_dataset_distribution(dataset, name=\"dataset\"):\n",
    "    total_samples = 0\n",
    "    label_counter = Counter()\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        # labels vêm em one-hot: [0,1] ou [1,0]\n",
    "        labels_np = labels.numpy()\n",
    "        class_indices = labels_np.argmax(axis=1)  # <-- Corrigir: pegar o índice da classe correta\n",
    "        total_samples += len(class_indices)\n",
    "        label_counter.update(class_indices)\n",
    "\n",
    "    print(f\"📊 {name.upper()} -> Total de imagens: {total_samples}\")\n",
    "    for label, count in sorted(label_counter.items()):\n",
    "        perc = (count / total_samples) * 100\n",
    "        print(f\"  Classe {int(label)} ({'Fogo' if label == 1 else 'Sem fogo'}): {count} imagens ({perc:.2f}%)\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccd9a0-5392-4f65-98b1-8c38ac99baff",
   "metadata": {},
   "source": [
    "Permite analisar o histórico de trino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3be343-b0cb-478c-ad86-fd0a08de3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    metrics = history.history.keys()\n",
    "    epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "    for metric in metrics:\n",
    "        if \"val_\" not in metric:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(epochs_range, history.history[metric], label=f\"Train {metric}\")\n",
    "            if f\"val_{metric}\" in metrics:\n",
    "                plt.plot(epochs_range, history.history[f\"val_{metric}\"], label=f\"Val {metric}\")\n",
    "            plt.title(f\"Training and Validation {metric.capitalize()}\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(metric.capitalize())\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6add7a0e-4c59-43c3-b53a-26f532fb50bc",
   "metadata": {},
   "source": [
    "Usada para avaliar o modelo, ou seja, se está a prever corretamente a classificação das imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a63966-c04a-435d-8061-94ade2bfcb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(model, dataset):\n",
    "    # 1. Previsões e rótulos reais\n",
    "    y_pred_probs = model.predict(dataset, verbose=0)\n",
    "    y_true = np.concatenate([y for _, y in dataset], axis=0)\n",
    "    y_true_int = np.argmax(y_true, axis=1)\n",
    "    y_pred_int = (y_pred_probs[:, 1] > 0.5).astype(int)\n",
    "\n",
    "    # 2. Contagem das classes\n",
    "    TP = np.sum((y_true_int == 1) & (y_pred_int == 1))\n",
    "    TN = np.sum((y_true_int == 0) & (y_pred_int == 0))\n",
    "    FP = np.sum((y_true_int == 0) & (y_pred_int == 1))\n",
    "    FN = np.sum((y_true_int == 1) & (y_pred_int == 0))\n",
    "\n",
    "    total = TP + TN + FP + FN\n",
    "\n",
    "    # 3. Cálculo das métricas com base nas fórmulas\n",
    "    accuracy   = (TP + TN) / total if total > 0 else 0.0\n",
    "    precision  = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall     = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1_score   = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    auc        = roc_auc_score(y_true_int, y_pred_probs[:, 1])\n",
    "\n",
    "    # Categorical crossentropy loss\n",
    "    eps = 1e-7\n",
    "    p = np.clip(y_pred_probs, eps, 1 - eps)\n",
    "    y = y_true\n",
    "    loss = -np.mean(np.sum(y * np.log(p), axis=1))\n",
    "\n",
    "    # Métricas específicas de detecção de incêndio\n",
    "    fdr = recall * 100  # ou (TP / (TP + FN)) * 100\n",
    "    ewr = ((FP + FN) / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "    # 4. Impressão\n",
    "    print(\"=== MÉTRICAS DE AVALIAÇÃO ===\")\n",
    "    print(f\"TP={TP}, TN={TN}, FP={FP}, FN={FN}\")\n",
    "    print(f\"Accuracy       : {accuracy:.4f}\")\n",
    "    print(f\"Precision      : {precision:.4f}\")\n",
    "    print(f\"Recall         : {recall:.4f}\")\n",
    "    print(f\"F1-Score       : {f1_score:.4f}\")\n",
    "    print(f\"AUC            : {auc:.4f}\")\n",
    "    print(f\"Loss    : {loss:.4f}\")\n",
    "    print(f\"FDR (Fire Detection Rate)      : {fdr:.2f} %\")\n",
    "    print(f\"EWR (Error Warning Rate)       : {ewr:.2f} %\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array([[TN, FP], [FN, TP]]))  # [[negativos reais], [positivos reais]]\n",
    "\n",
    "    # 5. Retorno opcional\n",
    "    return {\n",
    "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'auc': auc,\n",
    "        'loss': loss,\n",
    "        'fdr': fdr,\n",
    "        'ewr': ewr,\n",
    "        'confusion_matrix': np.array([[TN, FP], [FN, TP]])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efbeeb-8f1f-4870-b20f-21d6a869cb80",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557018a-5007-46f3-a95a-736444a80673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações gerais\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eca24-d327-4750-a0c5-9499613df972",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/UAVS_RawImages.csv\")\n",
    "image_paths = data['image_path'].values\n",
    "labels = data['label_bi'].values\n",
    "\n",
    "data = pd.read_csv(\"../Datasets/UAVS_AugmentedImages.csv\")\n",
    "image_paths_test = data['image_path'].values\n",
    "labels_test = data['label_bi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c11cd4-9967-44fb-aa04-b0fa52734f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir em treino, validação e teste (80/10/10)\n",
    "x_train, x_val, y_train, y_val = train_test_split(image_paths, labels, test_size=0.1, random_state=SEED, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed3cd3-124b-4623-853b-d0aff7320a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar datasets TensorFlow\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(preprocess_image).shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_ds = val_ds.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((image_paths_test, labels_test))\n",
    "test_ds = test_ds.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa957854-4e26-4283-8dec-1a1367a65e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_dataset_distribution(train_ds, name=\"train\")\n",
    "inspect_dataset_distribution(val_ds, name=\"val\")\n",
    "inspect_dataset_distribution(test_ds, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a55e24-d244-448d-93c4-324d992b8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [\n",
    "    ModelCheckpoint('Recriar_Estudo_2_UAVS_best.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad06811-9a42-487c-892b-9e15daf1522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d9da3-5fc6-46fb-98ea-fc5aa15b913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ff76a-83f8-499f-8d6d-eaa1e17e0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter o histórico em DataFrame\n",
    "history = pd.DataFrame(history.history)\n",
    "# Salvar em CSV\n",
    "history.to_csv('Recriar_Estudo_2_UAVS_train_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b318861-0411-4ffa-aa93-dd6e787199fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Recriar_Estudo_2_UAVS.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8ba9d-88a9-49e9-9754-8c9133c4627c",
   "metadata": {},
   "source": [
    "## Avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e480aea-7133-4397-91a1-d04e3a7093f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('Recriar_Estudo_2_UAVS.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5b1c1-cc7e-45cc-99f9-03d0ead49fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed63bb6-910c-4da7-b84f-538acbf9f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = load_model('Recriar_Estudo_2_UAVS_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a1cef-4c51-4825-b936-4652e9ebbd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999c938-e817-4195-bede-f0cbd0567e1f",
   "metadata": {},
   "source": [
    "## Testar no FLAME train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c75ff-0c52-4a30-9394-66a0449d1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/FLAME_train.csv\")\n",
    "image_paths_flame_train = data['image_path'].values\n",
    "labels_flame_train = data['label_bi'].values\n",
    "\n",
    "test_ds_flame_train = tf.data.Dataset.from_tensor_slices((image_paths_flame_train, labels_flame_train))\n",
    "test_ds_flame_train = test_ds_flame_train.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_flame_train, name=\"FLAME train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f97332-b439-41b3-9374-34c3594ff212",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_flame_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2539c-df28-4ca7-9023-8a202c21fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_flame_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757be33-89d3-4f6e-afc7-c53e805ff1bc",
   "metadata": {},
   "source": [
    "## Testar no FLAME test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dd046-9f87-4f28-83d3-cf0818a4a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/FLAME_test.csv\")\n",
    "image_paths_flame_test = data['image_path'].values\n",
    "labels_flame_test = data['label_bi'].values\n",
    "\n",
    "test_ds_flame_test = tf.data.Dataset.from_tensor_slices((image_paths_flame_test, labels_flame_test))\n",
    "test_ds_flame_test = test_ds_flame_test.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_flame_test, name=\"FLAME test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abba171-abab-4173-9e8e-01ab14ba87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_flame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97962c3-82b2-4ed0-97da-77dabb2b9e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_flame_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a526d80e-7ab2-43c9-beb7-9fdf347fed8a",
   "metadata": {},
   "source": [
    "## Testar no UAVS Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51c3a6-babf-48aa-8938-7bf0dbd630af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/UAVS_RawImages.csv\")\n",
    "image_paths_uavs_raw = data['image_path'].values\n",
    "labels_uavs_raw = data['label_bi'].values\n",
    "\n",
    "test_ds_uavs_raw = tf.data.Dataset.from_tensor_slices((image_paths_uavs_raw, labels_uavs_raw))\n",
    "test_ds_uavs_raw = test_ds_uavs_raw.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_uavs_raw, name=\"UAVS Raw Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b441f0-3a0c-4f36-9285-8c58a5366a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_uavs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7baebcd-fd32-4081-99db-9f9e338eb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_uavs_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff90e4-6e43-4e30-a1d5-fb8fa84c4bb0",
   "metadata": {},
   "source": [
    "## Testar no UAVS Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7682038-3935-46ab-b6dd-bb3787509c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/UAVS_AugmentedImages.csv\")\n",
    "image_paths_uavs_aug = data['image_path'].values\n",
    "labels_uavs_aug = data['label_bi'].values\n",
    "\n",
    "test_ds_uavs_aug = tf.data.Dataset.from_tensor_slices((image_paths_uavs_aug, labels_uavs_aug))\n",
    "test_ds_uavs_aug = test_ds_uavs_aug.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_uavs_aug, name=\"UAVS Augmented Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3b7df-c4e8-4c8d-8aad-90f55d68debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_uavs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53231a4-1633-42f6-8e1a-3a66e6792695",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_uavs_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab614afb-f0bb-4055-9c70-22299e3857b4",
   "metadata": {},
   "source": [
    "## Testar no FireMan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9ea8a-9b89-4c50-a834-9c0c722120ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/FireMan_test.csv\")\n",
    "image_paths_fireman = data['image_path'].values\n",
    "labels_fireman = data['label_bi'].values\n",
    "\n",
    "test_ds_fireman = tf.data.Dataset.from_tensor_slices((image_paths_fireman, labels_fireman))\n",
    "test_ds_fireman = test_ds_fireman.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_fireman, name=\"UAVS Augmented Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ada996-889f-4bc1-88e2-a8f6e3260da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_fireman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff71c19-e5b1-45d9-94e0-539f808ac0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_fireman)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
