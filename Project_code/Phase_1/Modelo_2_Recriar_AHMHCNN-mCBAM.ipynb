{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a35791-4f57-4efd-81d4-ce871a7ad21f",
   "metadata": {},
   "source": [
    "# Recriar Estudo 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bce6ac-eb3d-484d-9fba-0ce4638f216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1db65b-e46e-4687-8a46-842669a79717",
   "metadata": {},
   "source": [
    "**Ver se est√° a usar a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775613f9-11c0-44c1-9f39-22c75604ce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a7f2f9-a20f-4342-944d-fc72e88f0af1",
   "metadata": {},
   "source": [
    "**imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2572ebb-43f4-476d-9fb0-0f6370e4af82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Ativa o alocador ass√≠ncrono (melhora fragmenta√ß√£o de mem√≥ria)\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "import tensorflow as tf\n",
    "# Ativa a aloca√ß√£o din√¢mica de mem√≥ria (n√£o ocupa toda a mem√≥ria no in√≠cio)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(\"Erro ao definir memory growth:\", e)\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, \n",
    "                                     GlobalMaxPooling2D, Dense, Dropout, BatchNormalization, AveragePooling2D,\n",
    "                                     Concatenate, Flatten, LayerNormalization, Multiply, Add, Activation, Reshape)\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"TensorFlow Addons:\", tfa.__version__)\n",
    "print(\"NumPy:\", np.__version__)\n",
    "print(\"Pandas:\", pd.__version__)\n",
    "print(\"Matplotlib:\", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a131384-70c4-45ec-ac80-f8e9198900d1",
   "metadata": {},
   "source": [
    "## Arquitetura do Modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f721ad39-f1cd-4a22-95e8-8e0d53704d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention(input_feature, reduction_ratio=8):\n",
    "    channel = input_feature.shape[-1]\n",
    "\n",
    "    shared_dense_one = Dense(channel // reduction_ratio, activation='relu', kernel_initializer='glorot_uniform')\n",
    "    shared_dense_two = Dense(channel, activation='relu', kernel_initializer='glorot_uniform')\n",
    "\n",
    "    avg_pool = GlobalAveragePooling2D()(input_feature)\n",
    "    max_pool = GlobalMaxPooling2D()(input_feature)\n",
    "\n",
    "    avg_out = shared_dense_two(shared_dense_one(avg_pool))\n",
    "    max_out = shared_dense_two(shared_dense_one(max_pool))\n",
    "\n",
    "    cbam_feature = Add()([avg_out, max_out])\n",
    "    cbam_feature = Activation('relu')(cbam_feature)\n",
    "    cbam_feature = Reshape((1, 1, channel))(cbam_feature)\n",
    "\n",
    "    return Multiply()([input_feature, cbam_feature])\n",
    "\n",
    "# Aten√ß√£o espacial com layer norm, conv 7x7 e gating\n",
    "def spatial_attention(input_feature):\n",
    "    avg_pool = tf.reduce_mean(input_feature, axis=-1, keepdims=True)\n",
    "    max_pool = tf.reduce_max(input_feature, axis=-1, keepdims=True)\n",
    "    concat = Concatenate(axis=-1)([avg_pool, max_pool])\n",
    "    concat = LayerNormalization()(concat)\n",
    "\n",
    "    conv = Conv2D(1, kernel_size=7, padding='same', activation='relu')(concat)\n",
    "    gate = Conv2D(1, kernel_size=1, padding='same', activation='sigmoid')(concat)\n",
    "    gated = Multiply()([conv, gate])\n",
    "\n",
    "    return Multiply()([input_feature, gated])\n",
    "\n",
    "# Bloco AHC: convolu√ß√µes paralelas com pooling\n",
    "def AHC_block(input_tensor):\n",
    "    conv_3x3 = Conv2D(32, kernel_size=3, padding='same', activation='relu')(input_tensor)\n",
    "    conv_5x5 = Conv2D(32, kernel_size=5, padding='same', activation='relu')(input_tensor)\n",
    "    conv_7x7 = Conv2D(32, kernel_size=7, padding='same', activation='relu')(input_tensor)\n",
    "\n",
    "    pool_3x3 = AveragePooling2D(pool_size=2, strides=1, padding='same')(conv_3x3)\n",
    "    pool_5x5 = AveragePooling2D(pool_size=2, strides=1, padding='same')(conv_5x5)\n",
    "    pool_7x7 = AveragePooling2D(pool_size=2, strides=1, padding='same')(conv_7x7)\n",
    "\n",
    "    return Concatenate()([pool_3x3, pool_5x5, pool_7x7])\n",
    "\n",
    "# Modelo completo AHMHCNN-mCBAM\n",
    "def build_AHMHCNN_mCBAM(input_shape=(256, 256, 3), num_classes=2):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # MHCNN base convolucional\n",
    "    x = Conv2D(32, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Conv2D(48, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Conv2D(64, kernel_size=5, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = Dropout(0.02)(x)\n",
    "    x = Conv2D(32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.02)(x)\n",
    "\n",
    "    # Bloco AHC\n",
    "    x = AHC_block(x)\n",
    "\n",
    "    # Bloco mCBAM\n",
    "    x = channel_attention(x)\n",
    "    x = spatial_attention(x)\n",
    "\n",
    "    # Classifica√ß√£o\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(56, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(48, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# Criar o modelo\n",
    "model = build_AHMHCNN_mCBAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b26bfd-e7bd-448e-9862-99a59ece00b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "        tf.keras.metrics.AUC(),\n",
    "        tfa.metrics.F1Score(num_classes=2, average='macro')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c855bb-b8db-441f-8e95-7b8a966dd951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar resumo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2c7bb-b824-4c0b-8a30-3adf43feb167",
   "metadata": {},
   "source": [
    "## Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e059b75e-c052-4e98-8321-9a86498aabb0",
   "metadata": {},
   "source": [
    "Trata do pr√©-processamento das imagens, ou seja redimensiona para 224 X 224 pixels e normaliza [0,1] e coloca em one hot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0721c0a-5321-45cc-a301-b6281f40044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o auxiliar para carregar imagem\n",
    "def preprocess_image(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = image / 255.0\n",
    "    label = tf.one_hot(label, 2)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09965d75-99bf-4305-bce4-812851f38c34",
   "metadata": {},
   "source": [
    "Permite analisar a distribui√ß√£o dos datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7183b8f6-3af3-4537-ac18-9d56ae26e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_dataset_distribution(dataset, name=\"dataset\"):\n",
    "    total_samples = 0\n",
    "    label_counter = Counter()\n",
    "\n",
    "    for images, labels in dataset:\n",
    "        # labels v√™m em one-hot: [0,1] ou [1,0]\n",
    "        labels_np = labels.numpy()\n",
    "        class_indices = labels_np.argmax(axis=1)  # <-- Corrigir: pegar o √≠ndice da classe correta\n",
    "        total_samples += len(class_indices)\n",
    "        label_counter.update(class_indices)\n",
    "\n",
    "    print(f\"üìä {name.upper()} -> Total de imagens: {total_samples}\")\n",
    "    for label, count in sorted(label_counter.items()):\n",
    "        perc = (count / total_samples) * 100\n",
    "        print(f\"  Classe {int(label)} ({'Fogo' if label == 1 else 'Sem fogo'}): {count} imagens ({perc:.2f}%)\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ccd9a0-5392-4f65-98b1-8c38ac99baff",
   "metadata": {},
   "source": [
    "Permite analisar o hist√≥rico de trino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3be343-b0cb-478c-ad86-fd0a08de3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    metrics = history.history.keys()\n",
    "    epochs_range = range(len(history.history['loss']))\n",
    "\n",
    "    for metric in metrics:\n",
    "        if \"val_\" not in metric:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.plot(epochs_range, history.history[metric], label=f\"Train {metric}\")\n",
    "            if f\"val_{metric}\" in metrics:\n",
    "                plt.plot(epochs_range, history.history[f\"val_{metric}\"], label=f\"Val {metric}\")\n",
    "            plt.title(f\"Training and Validation {metric.capitalize()}\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(metric.capitalize())\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6494b6a-3516-46d2-a04e-a936a8a38a79",
   "metadata": {},
   "source": [
    "Usada para avaliar o modelo, ou seja, se est√° a prever corretamente a classifica√ß√£o das imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb25950-0684-4823-8c54-7c96e9f3ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliar_modelo(model, dataset):\n",
    "    # 1. Previs√µes e r√≥tulos reais\n",
    "    y_pred_probs = model.predict(dataset, verbose=0)\n",
    "    y_true = np.concatenate([y for _, y in dataset], axis=0)\n",
    "    y_true_int = np.argmax(y_true, axis=1)\n",
    "    y_pred_int = (y_pred_probs[:, 1] > 0.5).astype(int)\n",
    "\n",
    "    # 2. Contagem das classes\n",
    "    TP = np.sum((y_true_int == 1) & (y_pred_int == 1))\n",
    "    TN = np.sum((y_true_int == 0) & (y_pred_int == 0))\n",
    "    FP = np.sum((y_true_int == 0) & (y_pred_int == 1))\n",
    "    FN = np.sum((y_true_int == 1) & (y_pred_int == 0))\n",
    "\n",
    "    total = TP + TN + FP + FN\n",
    "\n",
    "    # 3. C√°lculo das m√©tricas com base nas f√≥rmulas\n",
    "    accuracy   = (TP + TN) / total if total > 0 else 0.0\n",
    "    precision  = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "    recall     = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "    f1_score   = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    auc        = roc_auc_score(y_true_int, y_pred_probs[:, 1])\n",
    "\n",
    "    # Categorical crossentropy loss\n",
    "    eps = 1e-7\n",
    "    p = np.clip(y_pred_probs, eps, 1 - eps)\n",
    "    y = y_true\n",
    "    loss = -np.mean(np.sum(y * np.log(p), axis=1))\n",
    "\n",
    "    # M√©tricas espec√≠ficas de detec√ß√£o de inc√™ndio\n",
    "    fdr = recall * 100  # ou (TP / (TP + FN)) * 100\n",
    "    ewr = ((FP + FN) / total) * 100 if total > 0 else 0.0\n",
    "\n",
    "    # 4. Impress√£o\n",
    "    print(\"=== M√âTRICAS DE AVALIA√á√ÉO ===\")\n",
    "    print(f\"TP={TP}, TN={TN}, FP={FP}, FN={FN}\")\n",
    "    print(f\"Accuracy       : {accuracy:.4f}\")\n",
    "    print(f\"Precision      : {precision:.4f}\")\n",
    "    print(f\"Recall         : {recall:.4f}\")\n",
    "    print(f\"F1-Score       : {f1_score:.4f}\")\n",
    "    print(f\"AUC            : {auc:.4f}\")\n",
    "    print(f\"Loss    : {loss:.4f}\")\n",
    "    print(f\"FDR (Fire Detection Rate)      : {fdr:.2f} %\")\n",
    "    print(f\"EWR (Error Warning Rate)       : {ewr:.2f} %\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(np.array([[TN, FP], [FN, TP]]))  # [[negativos reais], [positivos reais]]\n",
    "\n",
    "    # 5. Retorno opcional\n",
    "    return {\n",
    "        'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score,\n",
    "        'auc': auc,\n",
    "        'loss': loss,\n",
    "        'fdr': fdr,\n",
    "        'ewr': ewr,\n",
    "        'confusion_matrix': np.array([[TN, FP], [FN, TP]])\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87efbeeb-8f1f-4870-b20f-21d6a869cb80",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557018a-5007-46f3-a95a-736444a80673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes gerais\n",
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eca24-d327-4750-a0c5-9499613df972",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/UAVS_RawImages.csv\")\n",
    "image_paths = data['image_path'].values\n",
    "labels = data['label_bi'].values\n",
    "\n",
    "data = pd.read_csv(\"../Datasets/UAVS_AugmentedImages.csv\")\n",
    "image_paths_test = data['image_path'].values\n",
    "labels_test = data['label_bi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c11cd4-9967-44fb-aa04-b0fa52734f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(image_paths, labels, test_size=0.1, random_state=SEED, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed3cd3-124b-4623-853b-d0aff7320a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar datasets TensorFlow\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(preprocess_image).shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_ds = val_ds.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((image_paths_test, labels_test))\n",
    "test_ds = test_ds.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa957854-4e26-4283-8dec-1a1367a65e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_dataset_distribution(train_ds, name=\"train\")\n",
    "inspect_dataset_distribution(val_ds, name=\"val\")\n",
    "inspect_dataset_distribution(test_ds, name=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a55e24-d244-448d-93c4-324d992b8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o do agendamento de learning rate conforme o estudo\n",
    "def custom_lr_schedule(epoch, lr):\n",
    "    if epoch < 15:\n",
    "        return 1e-4\n",
    "    elif epoch < 25:\n",
    "        return 1e-5\n",
    "    else:\n",
    "        return 1e-6\n",
    "\n",
    "# Callbacks combinados\n",
    "callback = [\n",
    "    ModelCheckpoint('Recriar_Estudo_6_best.h5', monitor='val_loss', save_best_only=True, verbose=1),\n",
    "    LearningRateScheduler(custom_lr_schedule, verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad06811-9a42-487c-892b-9e15daf1522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d9da3-5fc6-46fb-98ea-fc5aa15b913f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17ff76a-83f8-499f-8d6d-eaa1e17e0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter o hist√≥rico em DataFrame\n",
    "history = pd.DataFrame(history.history)\n",
    "# Salvar em CSV\n",
    "history.to_csv('Recriar_Estudo_6_train_history.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3730d35-cac3-4fe9-af8c-f41fc5eeb694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Recriar_Estudo_6.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b8ba9d-88a9-49e9-9754-8c9133c4627c",
   "metadata": {},
   "source": [
    "## Avaliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd5b1c1-cc7e-45cc-99f9-03d0ead49fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a6155-013d-4c4c-9a7f-3fd08b1b1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best = load_model('Recriar_Estudo_6_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5e31c2-34a1-433f-97fa-63f4ef178bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a999c938-e817-4195-bede-f0cbd0567e1f",
   "metadata": {},
   "source": [
    "## Testar no FLAME train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c75ff-0c52-4a30-9394-66a0449d1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/FLAME_train.csv\")\n",
    "image_paths_flame_train = data['image_path'].values\n",
    "labels_flame_train = data['label_bi'].values\n",
    "\n",
    "test_ds_flame_train = tf.data.Dataset.from_tensor_slices((image_paths_flame_train, labels_flame_train))\n",
    "test_ds_flame_train = test_ds_flame_train.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_flame_train, name=\"FLAME train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95faa3f0-2aed-42f9-8b19-78c3083f5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_flame_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3037e-e7d4-4205-b4e4-5a91ab848db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_flame_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6757be33-89d3-4f6e-afc7-c53e805ff1bc",
   "metadata": {},
   "source": [
    "## Testar no FLAME test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0dd046-9f87-4f28-83d3-cf0818a4a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/FLAME_test.csv\")\n",
    "image_paths_flame_test = data['image_path'].values\n",
    "labels_flame_test = data['label_bi'].values\n",
    "\n",
    "test_ds_flame_test = tf.data.Dataset.from_tensor_slices((image_paths_flame_test, labels_flame_test))\n",
    "test_ds_flame_test = test_ds_flame_test.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_flame_test, name=\"FLAME test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed15cd-970e-4319-89ea-012763bbf63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_flame_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b527f68-3d87-46fa-bdf3-9ae49914c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_flame_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3858436-9af6-4f30-a677-a4c23e640a0b",
   "metadata": {},
   "source": [
    "## Testar no UAVS Raw Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc10b7-e6b7-43b0-ba7e-5214320ca4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/UAVS_RawImages.csv\")\n",
    "image_paths_uavs_raw = data['image_path'].values\n",
    "labels_uavs_raw = data['label_bi'].values\n",
    "\n",
    "test_ds_uavs_raw = tf.data.Dataset.from_tensor_slices((image_paths_uavs_raw, labels_uavs_raw))\n",
    "test_ds_uavs_raw = test_ds_uavs_raw.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_uavs_raw, name=\"UAVS Raw Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ccc399-e10e-4e35-b988-cd8fa9d43430",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_uavs_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03030399-e408-4486-bdb9-1dcbf02ee621",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_uavs_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d65478f-c60e-43aa-a5a8-873477bc3ebd",
   "metadata": {},
   "source": [
    "## Testar no UAVS Augmented Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266be61-01ab-4664-becb-c1dc34f34b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/UAVS_AugmentedImages.csv\")\n",
    "image_paths_uavs_aug = data['image_path'].values\n",
    "labels_uavs_aug = data['label_bi'].values\n",
    "\n",
    "test_ds_uavs_aug = tf.data.Dataset.from_tensor_slices((image_paths_uavs_aug, labels_uavs_aug))\n",
    "test_ds_uavs_aug = test_ds_uavs_aug.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_uavs_aug, name=\"UAVS Augmented Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536a74f-c118-4970-bfa4-34b71fc91351",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_uavs_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f28fe3-2c36-46da-9cf5-a8651c6e2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_uavs_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12be88-3cf0-432d-a6db-1a430c60567f",
   "metadata": {},
   "source": [
    "## Testar no FireMan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6250c-73a5-4df5-8332-56dd5034bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/FireMan_test.csv\")\n",
    "image_paths_fireman = data['image_path'].values\n",
    "labels_fireman = data['label_bi'].values\n",
    "\n",
    "test_ds_fireman = tf.data.Dataset.from_tensor_slices((image_paths_fireman, labels_fireman))\n",
    "test_ds_fireman = test_ds_fireman.map(preprocess_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "inspect_dataset_distribution(test_ds_fireman, name=\"UAVS Augmented Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4068a-023d-4f97-907a-832a0c8c360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model, test_ds_fireman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a1bb6-ce8f-402f-89c6-7570ec5940b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avaliar_modelo(model_best, test_ds_fireman)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
